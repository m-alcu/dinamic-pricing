{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellman optimality equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathit v_*(\\mathit s) & = \\max_a \\mathbb E\\Big[R_{t+1} + \\gamma\\mathit v_*(S_{t+1}) \\;|\\; S_t = \\mathit s, A_t = a\\Big] \\\\\n",
    " & = \\max_a \\sum_{s',r}p(s', r\\;|\\;s,a)\\Big[r+\\gamma\\mathit v_*(\\mathit s')\\Big], or\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathit q_*(\\mathit s, a) & = \\mathbb E\\Big[R_{t+1} + \\gamma\\max_{a'}q_{*}(S_{t+1}, a') \\;|\\; S_t = \\mathit s, A_t = a\\Big] \\\\\n",
    " & = \\sum_{s',r}p(s', r \\;| \\;s,a)\\Big[r+\\gamma\\max_{a'}q_{*}(s',a')\\Big],\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellman policy iteration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bellman policy iteration](https://miro.medium.com/max/700/1*bFfEAItW_IP651nBetX2uQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bellman policy iteration](https://miro.medium.com/max/700/1*Rt4dY1KHmMe8CvgnsI14gg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Programming Value iteration (Bellman):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q(s_t,a_t) \\leftarrow Q(s_t,a_t)+ \\sum_{s_{t+1}}p(s_{t+1}, r_t \\;| \\;s_t,a_t)\\Big[r_t+\\gamma\\max_{a'}Q(s_{t+1},a')\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q(s_t,a_t) \\leftarrow Q(s_t,a_t) + \\alpha\\Big[r_{r+1}+\\gamma r_{r+2}+...+\\gamma^{N-1} r_{r+N}-Q(s_t,a_t)\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-Learning Off-Policy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q(s_t,a_t) \\leftarrow Q(s_t,a_t)+ \\alpha \\Big [r_{t+1}+\\gamma \\max_{a'}Q(s_{t+1},a')- Q(s_t,a_t)\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARSA On-Policy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q(s_t,a_t) \\leftarrow Q(s_t,a_t)+ \\alpha \\Big [r_{t+1}+\\gamma Q(s_{t+1},a_{t+1})- Q(s_t,a_t)\\Big]$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
